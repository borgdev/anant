# Anant Graph Registry Architecture

> **PostgreSQL as Graph Registry/Catalog + Anant's Native Parquet Storage**

## ğŸ¯ Architecture Overview

This implementation aligns with **Anant's native Parquet+Polars architecture** by using PostgreSQL as a lightweight **graph registry/catalog** rather than full graph storage.

### ğŸ—ï¸ Architecture Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Anant Graph Registry                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PostgreSQL (Registry/Catalog)    â”‚  Parquet Files (Data)   â”‚
â”‚  â”œâ”€ Graph metadata & catalog      â”‚  â”œâ”€ Hypergraphs         â”‚
â”‚  â”œâ”€ User management               â”‚  â”œâ”€ Metagraphs          â”‚
â”‚  â”œâ”€ Access control                â”‚  â”œâ”€ Knowledge Graphs    â”‚
â”‚  â”œâ”€ Query history                 â”‚  â””â”€ All graph data      â”‚
â”‚  â””â”€ Audit trails                  â”‚                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           Ray Cluster (Distributed Computing)              â”‚
â”‚           Redis (Caching & Sessions)                       â”‚
â”‚           FastAPI (Registry API)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### âœ… Why This Approach is Correct

1. **Aligns with Anant's Native Storage**: Anant uses Parquet+Polars throughout its codebase
2. **PostgreSQL as Registry**: Optimized for metadata, not full graph storage  
3. **Performance**: Polars provides blazing-fast analytics on Parquet files
4. **Scalability**: Parquet files can be distributed across storage systems
5. **Compatibility**: Works seamlessly with existing Anant architecture

## ğŸ“‹ PostgreSQL Registry Schema

The registry schema is **lightweight and focused**:

### Core Tables

- **`graph_registry`** - Graph catalog with metadata and Parquet file paths
- **`users`** - User management and authentication
- **`graph_permissions`** - Access control for graphs  
- **`query_history`** - Analytics and usage tracking
- **`storage_locations`** - Storage backend configuration
- **`audit_logs`** - Security and compliance

### Sample Registry Entry

```sql
-- Graph registered in PostgreSQL catalog
INSERT INTO graph_registry (
    name, graph_type, storage_path, 
    node_count, edge_count, properties
) VALUES (
    'my_hypergraph', 'hypergraph', 
    './parquet_data/my_hypergraph.parquet',
    1000, 5000, 
    '{"format": "parquet", "engine": "polars"}'
);
```

## ğŸš€ Quick Start

### 1. Setup Registry Database

```bash
# Create the registry schema
python create_registry_schema.py
```

### 2. Deploy with Docker

```bash
# Deploy the registry-optimized stack
docker-compose -f docker-compose.registry.yml up -d

# Verify services
docker-compose ps
```

### 3. Run the Demo

```bash
# Demonstrate the registry architecture
python registry_architecture_demo.py
```

### 4. Start Registry API

```bash
# Run the FastAPI registry server
python registry_server.py
```

## ğŸ“Š Registry API Endpoints

### Graph Registry Operations

```bash
# List graphs in registry
curl http://localhost:8080/graphs

# Create graph registration
curl -X POST http://localhost:8080/graphs \
  -H "Content-Type: application/json" \
  -d '{"name": "my_graph", "graph_type": "hypergraph"}'

# Get graph metadata
curl http://localhost:8080/graphs/{graph_id}

# Get computed statistics
curl http://localhost:8080/graphs/{graph_id}/stats

# Execute distributed queries
curl -X POST http://localhost:8080/graphs/{graph_id}/query \
  -H "Content-Type: application/json" \
  -d '{"operation": "analyze", "parameters": {}}'
```

### Registry Statistics

```bash
# Overall registry stats
curl http://localhost:8080/registry/stats
```

## ğŸ’¾ Storage Architecture

### Parquet File Organization

```
parquet_data/
â”œâ”€â”€ hypergraphs/
â”‚   â”œâ”€â”€ research_collab.parquet      # Hypergraph data
â”‚   â””â”€â”€ social_network.parquet
â”œâ”€â”€ metagraphs/ 
â”‚   â”œâ”€â”€ ontology_mapping.parquet     # Metagraph entities/relations
â”‚   â””â”€â”€ concept_hierarchy.parquet
â”œâ”€â”€ knowledge_graphs/
â”‚   â”œâ”€â”€ biomedical_kg.parquet        # Knowledge graph triples
â”‚   â””â”€â”€ enterprise_kg.parquet
â””â”€â”€ metadata/
    â”œâ”€â”€ schemas/                     # Schema definitions
    â””â”€â”€ indices/                     # Precomputed indices
```

### High-Performance Operations

```python
import polars as pl
from anant.io.parquet_io import ParquetIO

# Anant's native Parquet operations
parquet_io = ParquetIO()

# Read hypergraph with Polars (blazing fast)
df = pl.scan_parquet("./parquet_data/my_hypergraph.parquet")

# Lazy evaluation for massive datasets  
result = (df
    .filter(pl.col("type") == "node")
    .group_by("category") 
    .len()
    .collect())

# Use Anant's hypergraph operations
hypergraph = parquet_io.load_hypergraph("./parquet_data/my_hypergraph.parquet")
```

## ğŸ”„ Data Flow

### Graph Creation Flow

1. **API Request** â†’ FastAPI registry server
2. **Generate Parquet Path** â†’ `./parquet_data/{graph_name}.parquet` 
3. **Register in PostgreSQL** â†’ Metadata only
4. **Create Parquet File** â†’ Using Anant's native storage
5. **Return Registry ID** â†’ For future operations

### Graph Query Flow

1. **Query Request** â†’ Registry API with graph ID
2. **Lookup Storage Path** â†’ From PostgreSQL registry
3. **Distributed Execution** â†’ Ray cluster + Parquet operations
4. **Return Results** â†’ High-performance analytics
5. **Log Usage** â†’ Query history for analytics

## ğŸ¯ Benefits of This Architecture

### âœ… Performance Benefits

- **Polars Speed**: Vectorized operations on Parquet files
- **Lazy Evaluation**: Process massive datasets efficiently  
- **Columnar Storage**: Optimized for analytical workloads
- **Compression**: Efficient storage with Snappy/LZ4

### âœ… Scalability Benefits

- **Distributed Storage**: Parquet files across multiple systems
- **Ray Computing**: Distributed graph operations
- **Registry Queries**: Fast metadata lookups
- **Caching**: Redis for frequently accessed data

### âœ… Architecture Benefits

- **Native Compatibility**: Aligns with Anant's existing codebase
- **Storage Flexibility**: Local, S3, GCS, Azure storage backends
- **Registry Focus**: PostgreSQL optimized for catalog operations
- **API Consistency**: REST API for all registry operations

## ğŸ› ï¸ Configuration

### Environment Variables

```bash
# PostgreSQL Registry
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres  
POSTGRES_DB=anant_registry

# Redis Caching
REDIS_URL=redis://localhost:6379/0

# Ray Distributed Computing
RAY_ADDRESS=ray://localhost:10001

# Parquet Storage
PARQUET_BASE_PATH=./parquet_data

# API Configuration  
JWT_SECRET=your_secret_key
DEBUG=false
```

### Storage Configuration

```python
# Configure storage backends in PostgreSQL
INSERT INTO storage_locations (
    name, storage_type, base_path, configuration
) VALUES (
    'local_parquet', 'local', './parquet_data',
    '{"format": "parquet", "compression": "snappy", "engine": "polars"}'
),
(
    's3_production', 's3', 's3://anant-graphs/',
    '{"region": "us-west-2", "compression": "lz4", "partitioning": "date"}'
);
```

## ğŸ“ˆ Monitoring & Analytics

### Registry Analytics

```sql
-- Graph usage analytics
SELECT 
    gr.name,
    gr.graph_type,
    COUNT(qh.id) as query_count,
    AVG(qh.execution_time_ms) as avg_execution_time,
    SUM(gr.file_size_bytes) as total_size
FROM graph_registry gr
LEFT JOIN query_history qh ON gr.id = qh.graph_id
GROUP BY gr.id, gr.name, gr.graph_type
ORDER BY query_count DESC;
```

### Performance Monitoring

- **Ray Dashboard**: http://localhost:8265
- **Registry API**: http://localhost:8080/health  
- **Jupyter Analysis**: http://localhost:8888
- **Optional Grafana**: http://localhost:3000

## ğŸ” Security & Access Control

### User Management

```sql
-- Create users
INSERT INTO users (username, email, password_hash, is_admin)
VALUES ('researcher', 'researcher@org.com', 'hashed_pw', false);

-- Grant graph access
INSERT INTO graph_permissions (graph_id, user_id, permission_type)
VALUES ('graph-uuid', 'user-uuid', 'read');
```

### Audit Trails

All operations are logged in `audit_logs` table:
- User actions  
- Graph access
- Query execution
- Registry modifications

## ğŸ§ª Testing & Validation

### Run Tests

```bash
# Test registry functionality
python -m pytest tests/test_registry.py

# Test Parquet operations  
python -m pytest tests/test_parquet_ops.py

# Integration tests
python -m pytest tests/test_integration.py
```

### Validate Architecture

```bash
# Run the architecture demo
python registry_architecture_demo.py

# Verify registry-Parquet alignment
python validate_architecture.py
```

## ğŸš€ Production Deployment

### Docker Compose (Recommended)

```bash
# Production deployment
docker-compose -f docker-compose.registry.yml up -d

# Scale Ray workers
docker-compose up --scale ray-worker=4 -d
```

### Kubernetes (Advanced)

```bash
# Deploy with Helm
helm install anant-registry ./charts/anant-registry

# Scale components
kubectl scale deployment ray-workers --replicas=6
```

## ğŸ“š Integration with Anant

This registry architecture **seamlessly integrates** with Anant's existing codebase:

```python
from anant.hypergraph.core import Hypergraph
from anant.metagraph.core.metagraph import Metagraph  
from anant.io.parquet_io import ParquetIO

# Registry manages metadata, Anant handles graph operations
registry_client = RegistryClient("http://localhost:8080")
parquet_io = ParquetIO()

# Load graph via registry
graph_info = registry_client.get_graph("my-graph-id")
hypergraph = parquet_io.load_hypergraph(graph_info["storage_path"])

# Use Anant's native operations
result = hypergraph.compute_centrality()
```

---

## ğŸ¯ Key Takeaway

This architecture **perfectly aligns** with Anant's native Parquet+Polars approach:

- âœ… **PostgreSQL**: Lightweight registry/catalog (metadata only)
- âœ… **Parquet**: Native graph data storage (Anant's approach)  
- âœ… **Polars**: High-performance analytics (Anant's engine)
- âœ… **Registry**: Discovery, access control, and management
- âœ… **Compatibility**: Seamless integration with existing Anant codebase

You were absolutely correct - Anant uses Parquet natively, so PostgreSQL should serve as a **graph registry**, not full graph storage! ğŸ¯